# backend/services/model2_service.py

import json
from typing import List, Dict, Optional

from backend.utils.prompt_loader import load_prompt
from backend.utils.text_tools import strip_control_markers


class Model2Service:
    """
    model2ï¼šè´Ÿè´£ä»å¯¹è¯å†å²ä¸­åˆ†æç”¨æˆ·çš„"è§‚å¿µ"ï¼Œå¹¶åœ¨æ¯è½®å¯¹è¯å‰
    ä¸º model1 ç”Ÿæˆå†…éƒ¨å»ºè®®ï¼›åœ¨å¯¹è¯ç»“æŸæ—¶ç”Ÿæˆå®Œæ•´è§‚å¿µæŠ¥å‘Šã€‚

    è¯´æ˜ï¼š
    - llm ç”± ChatService æ³¨å…¥ï¼ˆæ„é€ æ—¶æˆ– attach_llmï¼‰
    - é•¿æœŸç‰¹è´¨ä¿¡æ¯ trait_summary / trait_profile ç”± ChatService ç»Ÿä¸€ç»´æŠ¤ï¼Œ
      è°ƒç”¨æ—¶ä»¥å‚æ•°å½¢å¼ä¼ å…¥æœ¬æœåŠ¡ï¼Œä¸åœ¨æœ¬ç±»ä¸­é•¿æœŸå­˜å‚¨ã€‚
    """

    def __init__(self, llm=None):
        self.llm = llm

    def attach_llm(self, llm):
        """å…è®¸ ChatService åœ¨åˆå§‹åŒ–åæ³¨å…¥ LLMClientã€‚"""
        self.llm = llm

    async def analyze(
        self,
        session_history: List[Dict],
        user_input: str,
        mode: int,
        topic_id: Optional[int],
        topic_title: Optional[str] = None,      # ğŸ†• v1.4
        topic_tags: Optional[List[str]] = None, # ğŸ†• v1.4
        trait_summary: str = "",
        trait_profile: str = "",
    ) -> dict:
        """
        æ¯è½®å¯¹è¯å‰è°ƒç”¨ï¼š
        - ç»“åˆå†å²å¯¹è¯ / æ¨¡å¼ /ï¼ˆå¯é€‰ï¼‰è¯é¢˜ /ï¼ˆå¯é€‰ï¼‰é•¿æœŸç‰¹è´¨
        - ç”Ÿæˆå¯¹ model1 çš„"å†…éƒ¨å¯¹è¯å»ºè®®"ï¼ˆadviceï¼‰ï¼Œç”¨æˆ·ä¸å¯è§ã€‚
        - åˆ¤æ–­æ˜¯å¦å·²æ•æ‰åˆ°è¶³å¤Ÿè§‚å¿µï¼ˆreport_readyï¼‰

        ğŸ†• v1.4 å˜æ›´ï¼š
        - æ·»åŠ  topic_title å’Œ topic_tags å‚æ•°
        - ä¸å†ä¾èµ– TOPICS å­—å…¸
        - ç”± ChatService ä¼ å…¥è¯é¢˜å…ƒæ•°æ®

        è¿”å›ç»“æ„ï¼š
        {
            "advice": str,     # ä¾› model1 ä½¿ç”¨çš„å†…éƒ¨å»ºè®®
            "signals": {
                "report_ready": bool  # æ˜¯å¦å¯ä»¥ç”ŸæˆæŠ¥å‘Š
            }
        }
        """
        if self.llm is None:
            # é˜²å¾¡å¼ï¼šå°šæœªæ³¨å…¥ llm æ—¶é¿å…å´©æºƒ
            return {"advice": "", "signals": {"report_ready": False}}

        # ================================
        # 1. åŠ è½½åˆ†ææç¤ºè¯ï¼ˆç”±æç¤ºè¯å·¥ç¨‹åŒå­¦ç»´æŠ¤ï¼‰
        # ================================
        if mode == 1:
            prompt_path = "model2/opinion_analysis_mode1.txt"
        else:
            prompt_path = "model2/opinion_analysis_mode2.txt"

        system_prompt = load_prompt(prompt_path)

        # ğŸ†• v1.4ï¼šè‹¥ä¸º mode1ï¼Œæ³¨å…¥è¯é¢˜å…ƒæ•°æ®ï¼ˆè€Œéä»TOPICSå­—å…¸æŸ¥è¯¢ï¼‰
        if mode == 1 and topic_title:
            system_prompt += (
                "\n\n# æœ¬æ¬¡å¯¹è¯çš„ç›®æ ‡è¯é¢˜ä¸è§‚å¿µæ ‡ç­¾ï¼š\n"
                f"- è¯é¢˜ï¼š{topic_title}\n"
            )
            if topic_tags:
                tags_str = "ã€".join(topic_tags)
                system_prompt += f"- æ ‡ç­¾ï¼š{tags_str}\n"
            system_prompt += "è¯·åœ¨åˆ†ææ—¶ç‰¹åˆ«èšç„¦äºè¯¥è¯é¢˜ç»´åº¦ã€‚"

        # æ³¨å…¥é•¿æœŸç‰¹è´¨ä¿¡æ¯ï¼ˆç”± ChatService ç»Ÿä¸€æä¾›ï¼‰
        if trait_summary:
            system_prompt += (
                "\n\n# ç”¨æˆ·é•¿æœŸç‰¹è´¨æ€»ç»“ï¼ˆä¸€å¥è¯ï¼‰ï¼š\n"
                f"{trait_summary}"
            )

        if trait_profile:
            system_prompt += (
                "\n\n# ç”¨æˆ·é•¿æœŸç‰¹è´¨ç”»åƒï¼ˆä¾›å‚è€ƒï¼Œä¸å¿…é€æ¡å¼•ç”¨ï¼‰ï¼š\n"
                f"{trait_profile}"
            )

        # ================================
        # 2. æ„é€  user_promptï¼ˆè¾“å…¥ç»™ LLMï¼‰
        # ================================
        formatted_history = self._format_history(session_history)

        user_prompt = (
            "ä»¥ä¸‹æ˜¯å½“å‰å¯¹è¯çš„å†å²ï¼Œè¯·æ ¹æ®ç³»ç»Ÿæç¤ºä¸­çš„è¦æ±‚è¿›è¡Œåˆ†æã€‚"
            "ã€å¯¹è¯å†å²ã€‘\n"
            f"{formatted_history}\n\n"
        )

        # ================================
        # 3. è°ƒç”¨ LLMï¼Œå¾—åˆ°å»ºè®®æ–‡æœ¬
        # ================================
        advice_text = ""
        async for chunk in self.llm.chat_stream(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            history=[],
        ):
            advice_text += chunk

        advice_text = strip_control_markers(advice_text).strip()

        # ================================
        # 4. è§£æ JSON æ ¼å¼ï¼ˆå®¹é”™å¤„ç†ï¼‰
        # ================================
        try:
            # å°è¯•æå– JSONï¼ˆå¯èƒ½åŒ…è£¹åœ¨ markdown ä»£ç å—ä¸­ï¼‰
            if "```json" in advice_text:
                json_match = advice_text.split("```json")[1].split("```")[0]
                advice_data = json.loads(json_match.strip())
            elif advice_text.startswith("{"):
                advice_data = json.loads(advice_text)
            else:
                # å¦‚æœä¸æ˜¯ JSONï¼Œåˆ™è§†ä¸ºçº¯æ–‡æœ¬å»ºè®®
                advice_data = {
                    "advice": advice_text,
                    "report_ready": False
                }
        except (json.JSONDecodeError, IndexError):
            # JSON è§£æå¤±è´¥ï¼Œé™çº§å¤„ç†
            advice_data = {
                "advice": advice_text,
                "report_ready": False
            }

        return {
            "advice": advice_data.get("advice", ""),
            "signals": {
                "report_ready": bool(advice_data.get("report_ready", False))
            }
        }

    async def final_report(
        self,
        full_history: List[Dict],
        mode: int,
        topic_id: Optional[int],
        topic_title: Optional[str] = None,      # ğŸ†• v1.4
        topic_tags: Optional[List[str]] = None, # ğŸ†• v1.4
        trait_summary: str = "",
        trait_profile: str = "",
    ) -> str:
        """
        å¯¹è¯ç»“æŸåè°ƒç”¨ï¼š
        - åŸºäºæœ¬æ¬¡å®Œæ•´å¯¹è¯å†å²
        - ç”Ÿæˆä¸€ä»½"è§‚å¿µåˆ†ææŠ¥å‘Š"ï¼ˆç»™ç”¨æˆ·çœ‹çš„ï¼‰

        ğŸ†• v1.4 å˜æ›´ï¼š
        - æ·»åŠ  topic_title å’Œ topic_tags å‚æ•°
        - ä¸å†ä¾èµ– TOPICS å­—å…¸
        - ç”± ChatService ä¼ å…¥è¯é¢˜å…ƒæ•°æ®

        mode:
        - 1ï¼šè¯é¢˜æµ‹è¯•æ¨¡å¼ï¼Œæœ‰è¯é¢˜ä¸è§‚å¿µæ ‡ç­¾
        - 2ï¼šéšä¾¿èŠèŠæ¨¡å¼ï¼Œæ— å›ºå®šè¯é¢˜
        """
        if self.llm is None:
            return ""

        # ================================
        # 1. åŠ è½½"æœ€ç»ˆæŠ¥å‘Š"æç¤ºè¯
        # ================================
        if mode == 1:
            prompt_path = "model2/final_report_mode1.txt"
        else:
            prompt_path = "model2/final_report_mode2.txt"

        system_prompt = load_prompt(prompt_path)

        # ğŸ†• v1.4ï¼šmode1 æ—¶æ³¨å…¥è¯é¢˜å…ƒæ•°æ®ï¼ˆè€Œéä»TOPICSå­—å…¸æŸ¥è¯¢ï¼‰
        if mode == 1 and topic_title:
            system_prompt += (
                "\n\n# æœ¬æ¬¡è§‚å¿µæŠ¥å‘Šå¯¹åº”çš„è¯é¢˜ä¿¡æ¯ï¼š\n"
                f"- è¯é¢˜ï¼š{topic_title}\n"
            )
            if topic_tags:
                tags_str = "ã€".join(topic_tags)
                system_prompt += f"- æ ‡ç­¾ï¼š{tags_str}\n"
            system_prompt += "è¯·å›´ç»•è¯¥è¯é¢˜ç»´åº¦ï¼Œå¯¹ç”¨æˆ·åœ¨æœ¬æ¬¡å¯¹è¯ä¸­çš„è§‚ç‚¹è¿›è¡Œç³»ç»Ÿæ€§åˆ†æã€‚"

        # æ³¨å…¥é•¿æœŸç‰¹è´¨ä¿¡æ¯ï¼Œå¸®åŠ©æŠ¥å‘Šä¸æ—¢æœ‰ç”»åƒä¿æŒä¸€è‡´
        if trait_summary:
            system_prompt += (
                "\n\n# å·²æœ‰çš„ç”¨æˆ·ç‰¹è´¨æ€»ç»“ï¼ˆä¸€å¥è¯ï¼‰ï¼š\n"
                f"{trait_summary}"
            )

        if trait_profile:
            system_prompt += (
                "\n\n# å·²æœ‰çš„ç”¨æˆ·ç‰¹è´¨ç”»åƒï¼ˆæ­¤å‰ä¼šè¯çš„æ•´ä½“åˆ†æï¼‰ï¼š\n"
                f"{trait_profile}"
            )

        # ================================
        # 2. æ ¼å¼åŒ–å®Œæ•´å†å²
        # ================================
        formatted_history = self._format_history(full_history)

        user_prompt = (
            "ä»¥ä¸‹æ˜¯æœ¬æ¬¡å®Œæ•´å¯¹è¯çš„å†å²ï¼Œè¯·æ ¹æ®ç³»ç»Ÿæç¤ºè¯çš„è¦æ±‚ï¼Œ"
            "ç”Ÿæˆä¸€ä»½é¢å‘ç”¨æˆ·çš„è§‚å¿µåˆ†ææŠ¥å‘Šã€‚\n\n"
            "ã€æœ¬æ¬¡å¯¹è¯å®Œæ•´å†å²ã€‘\n"
            f"{formatted_history}"
        )

        # ================================
        # 3. è°ƒç”¨ LLM å¾—åˆ°å®Œæ•´æŠ¥å‘Š
        # ================================
        report_text = ""
        async for chunk in self.llm.chat_stream(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            history=[],
        ):
            report_text += chunk

        report_text = strip_control_markers(report_text).strip()
        return report_text

    # =====================================
    # å·¥å…·å‡½æ•°ï¼šæ ¼å¼åŒ–å†å²ï¼Œé¿å… LLM çœ‹åˆ°åŸå§‹ Python dict
    # =====================================
    def _format_history(self, history: List[Dict]) -> str:
        """
        å°† [{"role": "...", "content": "..."}] æ ¼å¼çš„å†å²ï¼Œ
        è½¬æ¢ä¸ºæ›´æ˜“è¯»çš„å¤šè½®å¯¹è¯æ–‡æœ¬ã€‚
        """
        lines = []
        for turn in history:
            role = turn.get("role", "")
            content = turn.get("content", "")

            if role == "user":
                prefix = "ç”¨æˆ·ï¼š"
            elif role == "assistant":
                prefix = "åŠ©æ‰‹ï¼š"
            else:
                prefix = f"{role}ï¼š"

            lines.append(f"{prefix}{content}")
        return "\n".join(lines)
